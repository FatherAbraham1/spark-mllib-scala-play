<html>
<head>
    <title>Twitter Sentiment Analysis with Apache Spark, MLlib, Scala, Akka, and Play Framework</title>
</head>
<body>
<div>
    <h2 id="twitter-sentiment-analysis">Twitter Sentiment Analysis</h2>
    <h3>powered by Apache Spark, MLlib, Scala, Akka, and Play Framework</h3>

    <p>
        With this tutorial template we show how to automatically classify the sentiment of Twitter messages leveraging the Typesafe Stack and Apache Spark. These messages are classified as either positive or negative with respect to a query term. Users who want to research the sentiment of products before purchase, or companies that want to monitor the public sentiment of their brands can make use of this kind of application. The Activator template will consist of a backend component using Scala, Spark, Akka and the Play Framework in their most recent versions. The core part will demonstrate the usage of machine learning algorithms for classifying the sentiment of Twitter messages using Apache Spark and MLlib. The fundamental idea of sentiment classification used in this template is based on <a href="http://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf"  target="_blank">the paper by Alec Go et al.]</a> and its related implementation by <a  href="http://www.sentiment140.com"  target="_blank">Sentiment140</a>.
    </p>
</div>
<div>
    <h2 id="setup-instructions">Setup Instructions</h2>

    <p>
      <ol>
        <li>
      To run the application you will need <a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html"  target="_blank">Java </a> and either <a href="http://www.scala-sbt.org" target="_blank">SBT</a> or <a href="https://typesafe.com/activator" target="_blank">Activator</a> installed.</li>

    <li>Insert your Twitter access and consumer key/token pairs in <a href="#code/conf/application.conf">conf/application.conf</a>.
        For generating a token, please refer to <a
            href="https://dev.twitter.com/oauth/overview/application-owner-access-tokens" target="_blank">https://dev.twitter.com</a>.
    </li>
</ol>
</div><div><h2 id="starting-activator-or-sbt">Starting Activator or SBT</h2>

<p>Open a terminal and navigate to the root directory of this project</p>

<p>If you have Activator installed and it is in your path you can use Activator&rsquo;s UI with <code>activator ui</code>. It will start Activator and open the web-based UI in your browser automatically. (If not, open <a href="http://localhost:8888" target="_blank">localhost:8888</a> in your browser.)</p>
<p>With in the Activator UI you can use the <a class="shortcut" href="#run">run</a> link to start the Twitter Sentiment Analysis Application.</p>

<p>
If you want to start it via SBT use <code>sbt run</code> and navigate your browser to <a href="http://localhost:9000" target="_blank">localhost:9000</a>.
</p>

<p>
  If starting the application takes a very long time or even times out it may be due to a known <a href="https://github.com/typesafehub/activator/issues/1036">Activator issue</a>.
  In that case do the following before starting with <code>sbt run</code></p>
    <ul>
      <li>Delete the sbt-fork-run.sbt file</li>
      <li>Remove the line <code>fork in run := true</code>(added automatically when you start activator) from the bottom of build.sbt</li>
    </ul>
<p>
  Without the fork option, which is needed by Activator the application should start within a few seconds.
</p>
</div><div><h2 id="building-and-testing">Building and Testing</h2>

<p>To ensure that the basic environment is working, compile the code and run the tests. You can use the Activator UI&rsquo;s <a class="shortcut" href="#test">test</a> link or the sbt command <code>sbt test</code>.</p>

<p>All dependencies are downloaded, the code is compiled, and the tests are executed. This will take a while the first time and the tests should pass without error.</p>
</div>

<div>
    <h2 id="classification-workflow">Classification Workflow</h2>

    <p>
        The following diagram shows the actor communication workflow for classification:
    </p>

    <img src="tutorial/images/actors.jpg"/>

    <p>The <a href="#code/app/controllers/Application.scala">Application</a> controller serves HTTP requests from the client/browser and obtains <code>ActorRefs</code> for <a href="#code/app/actors/EventServer.scala">EventServer</a>, <a href="#code/app/actors/StatisticsServer.scala">StatisticsServer</a> and <a href="#code/app/actors/Director.scala">Director</a>.</p>

<p>The <a href="#code/app/actors/Director.scala">Director</a> is the root of the Actor hierarchy, which creates all other durable (long lived) actors except <a href="#code/app/actors/StatisticsServer.scala">StatisticsServer</a>  and <a href="#code/app/actors/EventServer.scala">EventServer</a>. Besides supervision of the child actors it builds the bridge between Play and Akka by handing over the <a href="#code/app/actors/Classifier.scala">Classifier</a> <code>ActorRefs</code> to the controller. Moreover, when trainings of the estimators within <a href="#code/app/actors/BatchTrainer.scala">BatchTrainer</a> and <a href="#code/app/actors/OnlineTrainer.scala">OnlineTrainer</a> are finished, this actor passes the latest Machine Learning models to the <a href="#code/app/actors/StatisticsServer">StatisticsServer</a> (see figure below). For the <a href="#code/app/actors/OnlineTrainer">OnlineTrainer</a> statistics generation is scheduled every 5 seconds.
</p>


The <a href="#code/app/actors/Classifier.scala">Classifier</a> creates a <a href="#code/app/actors/Classifier.scala">FetchResponseHandler</a> actor and tells the <code>TwitterHandler</code> with a <code>Fetch</code> message (and the <code>ActorRef</code> of the <a href="#code/app/actors/Classifier.scala">FetchResponseHandler</a>) to get the latest tweets by a given token or query.

Once the <code>TwitterHandler</code> has fetched some Tweets, the <code>FetchResponse</code> is sent to the <a href="#code/app/actors/Classifier.scala">FetchResponseHandler</a>.

The <a href="#code/app/actors/Classifier.scala">FetchResponseHandler</a> creates a <code>TrainingModelResponseHandler</code> actor and tells the <a href="#code/app/actors/BatchTrainer.scala">BatchTrainer</a> and <a href="#code/app/actors/OnlineTrainer.scala">OnlineTrainer</a> to pass the latest model to <code>TrainingModelResponseHandler</code>. It registers itself as a monitor for <code>TrainingModelResponseHandler</code> and when this actor terminates it stops itself as well.

The <code>TrainingModelResponseHandler</code> collects the models, vectorizes Tweets makes predictions and sends the results to the original sender (the <a href="#code/app/controllers/Application.scala">Application</a> controller). The original sender is passed through the ephemeral (short lived) actors, indicated by the yellow dotted line in the figure above.

</div>
<div>
  <h2>Tell don't Ask</h2>
  <p>
  The standard way of sending messages to actors in Akka is using the tell pattern, which is a fire-and-forget approach. Alternatively Akka
  supports the ask pattern, which returns a future as response for a sent message. This is very convenient for some scenarios like
  bridging a Play controller with an Akka actor system as you can see implemented in the <a href="#code/app/controllers/Application.scala">Application</a> controller. By using a future the application
  doesn't have to block the current thread to handle the task. This saves resources which can be used for example to handle more requests concurrently.
  However there are tradeoffs that come with the ask pattern. Every time an actor asks another actor for a response using futures a new <code>PromiseActorRef</code> is created. This is a waste of resources.
  Additionally using the ask pattern requires a timeout to be defined. This leads often to hard to debug applications, as stacktraces don't give you a clue which actor timed out. This is due to the fact, that futures
  don't have names like actors. In a larger application it is also difficult to set the right value for a timeout so that various timeouts set at different places in the application work together in a sensible way.
  </p>
  <p>
  To avoid all that it is preferable to use the fire-and-forget approach with the lightweight tell pattern. In this application we used the so called <bold>"cameo pattern"</bold> defined by Jamie Allen in his book <a href="http://shop.oreilly.com/product/0636920028789.do">Effective Akka</a>.
  </p>
  <p>
  All participants of this pattern can be found in the <a href="#code/app/actors/Classifier.scala">Classifier</a> file. The <code>Classifier</code> creates the <code>FetchResponseHandler</code>
  and passes its reference to the <code>TwitterHandler</code> telling it to send the fetched tweets to the handler instead of itself.
  <p>When we provide a different sender reference we cannot use the exclamation mark syntax <code>twitterHandler ! Fetch(token)</code> but
  have to use the <code>tell</code> method directly <code>twitterHandler.tell(Fetch(token), handler)</code>.</p>

  The <code>FetchResponseHandler</code> creates a <code>TrainingModelResponseHandler</code> which it sends to the <code>OnlineTrainer</code> and <code>BatchTrainer</code> as sender reference.
  The <code>TrainingModelResponseHandler</code> is the actor which collects all results and only sends the final <code>ClassificationResult</code> message to the original sender when all result have been received.
  The original sender (<a href="#code/app/controllers/Application">Application</a> controller) is passed through all of these actors.
  </p>

  <p>
    You might have noticed the timeout messages <code>FetchResponseTimeout</code> and <code>TrainingModelRetrievalTimeout</code> in the <a href="#code/app/actors/Classifier.scala">Classifier</a> file.
    As mentioned earlier with the ask pattern you have to define an implicit timeout, as you can see in the <a href="#code/app/controllers/Application">Application</a> controller.
    When you use tell instead you don't have to do that but if you want you can still enforce timeout semantics on the request by scheduling
    a timeout message that you send to yourself. In regards to the <code>TrainingModelResponseHandler</code> it means that the handler is scheduling a <code>TrainingModelRetrievalTimeout</code> to be sent in 3 seconds.
    If the handler doesn't receive a result from the online or batch trainer beforehand it will send the timeout message to the original sender. However if it receives the result in time it will cancel the scheduler and return the actual results.
  </p>
  <p>
    As you can see from the code using the cameo actors (<code>FetchResponseHandler</code> and <code>TrainingModelResponseHandler</code>) avoids the use of any ask pattern and its associated problems.
  </p>
</div>
<div>
    <h2 id="model-training-and-statistics">Model Training and Statistics</h2>

    <p>
      The following diagram shows the actors involved in training the machine learning estimators and serving statistics about their predictive performance:

        <img src="tutorial/images/actors2.jpg"/>

<p>
  The <a href="#code/app/actors/BatchTrainer.scala">BatchTrainer</a> receives a <code>Train</code> message as soon as a corpus (a collection of labeled tweets) has been initialized. This corpus is initialized by the <a href="#code/app/actors/CorpusInitializer.scala">CorpusInitializer</a> and can either be created on-the-fly via Spark's <code>TwitterUtils.createStream</code> (with automatic labeling by using emoticons ":)" and ":(") or a static corpus provided by <a href="http://www.sentiment140.com">Sentiment140</a> which is read from a CSV file. Which one to choose can be configured via <code>ml.corpus.initialization.streamed</code> in <a href="#code/conf/application.conf">conf/application.conf</a>. For batch training we use the high-level <code>org.apache.spark.ml</code> API. We use <bold>Grid Search Cross Validation</bold> to get the best hyperparameters for our <code>LogisticRegression</code> model.
</p>
<p>
The <a href="#code/app/actors/OnlineTrainer.scala">OnlineTrainer</a> receives a <code>Train</code> message with a corpus (an <code>RDD[Tweet]</code>) upon successful initialization just like the <a href="#code/app/actors/BatchTrainer.scala">BatchTrainer</a>. For the online learning approach we use the experimental <code>StreamingLogisticRegressionWithSGD</code> estimator which, as the name implies, uses <bold>Stochastic Gradient Descent</bold> to update the model continually on each Mini-Batch (RDD) of the <code>DStream</code> created via <code>TwitterUtils.createStream</code>.
</p>
<p>
The <a href="#code/app/actors/StatisticsServer.scala">StatisticsServer</a> receives <code>OnlineTrainerModel</code> and <code>BatchTrainerModel</code> messages and creates performance metrics like <bold>Accuracy, Area under the ROC Curve</bold> and so forth which in turn are forwarded to the subscribed <code>EventListeners</code> and finally sent to the client (browser) via <bold>Web Socket</bold>.
</p>
<p>
The <a href="#code/app/actors/EventListener.scala">EventListener</a>s are created for each client via the Play Framework built-in <code>WebSocket.acceptWithActor</code>. <code>EventListeners</code> subscribe for <a href="#code/app/actors/EventServer.scala">EventServer</a> and <a href="#code/app/actors/StatisticsServer.scala">StatisticsServer</a>. When the connections terminate (e.g. browser window is closed) the respective <code>EventListener</code> shuts down and unsubscribes from <code>EventServer</code> and/or <code>StatisticsServer</code> via the Actor's <code>postStop()</code> hook.
</p>
<p>
The <a href="#code/app/actors/EventServer.scala">EventServer</a> is created by the <a href="#code/app/controllers/Application.scala">Application</a> controller and forwards event messages (progress of corpus initialization) to the client (also via <code>Web Socket</code>).
</p>
</div>
    <div>
        <h2 id="machine-learning">Machine Learning</h2>
        <p>
            In this application we implemented two approaches to solve the classification problem
            (see <a target="_blank" href="https://en.wikipedia.org/wiki/Statistical_classification">statistical
            classification on Wikipedia</a> for more information about the problem).
        </p>
        <h3>The classic approach</h3>
        <p>
            The classic approach is to use a classification algorithm (we used <a
            href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a>) with supervised training.
            In our case that meant creating a set of labeled tweets - we actually didn't create this set ourselves, but
            got it from <a target="_blank" href="http://sentiment140.com">Sentiment140</a>. They did do a great job, so
            if you're interested be sure to check them out - and feed it to the algorithm. The following diagram shows
            how this is done by the <a href="#code/app/actors/BatchTrainer.scala:42">batch trainer</a>.
        </p>
        <img src="tutorial/images/batch_training.jpg"
             alt="Flow diagram of the training performed by the batch trainer"/>
        <p>
            As you can see the batch model training consists of three parts.
        </p>
        <ol>
            <li>
                An estimator is created. In our implementation we use a <a
                href="https://en.wikipedia.org/wiki/Feature_hashing">HashingTF</a> to preprocess the data and <a
                href="https://en.wikipedia.org/wiki/Logistic_regression">logististic
                regression</a> as the estimation algorithm.
                <br/>
                Spark 1.5 introduces the idea of <a href="http://spark.apache.org/docs/latest/ml-guide.html#pipeline">pipelines</a>.
                A pipeline by itself is just a description of a workflow. Take the following example.
                <p id="pipeline">
                    Your input is a tweet. Before you feed it to the evaluation algorithm you may want to remove stop
                    words, stem the resulting text and perform whatever pre-processing step comes to mind. After that
                    you may want to perform the HashingTF on the text. This three steps have to be performed for every
                    tweet in your dataset. With Spark 1.5 you create the various pre-processing objects and the
                    evaluation algorithm object (with their respective parameters) and put in the pipeline. The created
                    pipeline can now be used by the cross validation as an evaluator (instead of only the evaluation
                    algorithm).
                </p>
                <p>
                    And this is what we've done in the application. We created a pipeline, added pre-processing steps
                    (see the chapter about pre-processing for more information), added HashingTF and logistic regression
                    and used it as the evaluator for the cross validation.
                </p>
            </li>
            <li>
                A <a target="_blank" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search">parameter
                grid</a> is used to try different parameter values of the estimator.
            </li>
            <li>
                Cross validation is used to prevent overfitting (not only that, read more about <a
                href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">cross validation on Wikipedia</a>).
            </li>
        </ol>
        <h3>The <i>online</i> way</h3>
        <p>
            This approach is inspired by the work of the guys from <a target="_blank" href="sentiment140.com">sentiment140.com</a>.
            They wrote about it in their paper <a
            href="http://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf">Twitter Sentiment
            Classification using Distant Supervision</a>. We use a similar approach. In the following diagram you see
            how the approach works.
        </p>
        <img src="tutorial/images/online_training.jpg" alt="Flow diagram of the distant supervision approach"/>
        <p>
            This approach consists of four steps.
        </p>
        <ol>
            <li>
                Collect a set of tweets (you can define the size of the set in the <a
                href="#code/conf/application.conf:47">application.conf</a> with the parameter
                ml.corpus.initialization.tweets). We collect this set with the <a
                href="https://dev.twitter.com/streaming/public">streaming api of twitter</a>, <a
                href="http://twitter4j.org/en/index.html">Twitter4j</a> and the TwitterUtils provided by spark.
            </li>
            <li>
                Use distant supervision to label the tweets. This is done by labeling the tweets based on various
                indicators. We use emoticons as the indicator of the sentiment of a tweet. If a tweet contains a
                positive emoticon (like ":)" or ";)") it is labeled positive. Negative emoticons lead to a negative
                label (<a href="#code/app/features/Normalizable.scala:22">list of emoticons and their labels</a>). If a
                tweet contains emoticons of both types we use the first emoticon we find as the indicator.
            </li>
            <li>
                The <a href="#code/app/actors/OnlineTrainer.scala:66">OnlineTrainer opens a stream</a>, performs the
                pre-processing steps on each tweet and <a href="#code/app/actors/OnlineTrainer.scala:70">hands the set
                of tweets over to the evaluator</a>.
            </li>
            <li>
                The online trainer uses StreamingLogisticRegressionWithSGD as the evaluator.
                StreamingLogisticRegressionWithSGD is an implementation (provided by Spark) of logistic regression that
                supports streaming. This is accomplished by using <a
                href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">stochastic gradient descent</a> instead
                of the normal <a href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a> (used by
                logistic regression).
            </li>
        </ol>
        <h3 id="pre-processing">The pre-processing</h3>
        Spark in it's current version (by the time of writing this it's 1.5.2) has one flaw, if you want to share your
        code between the classic and the online evaluator. The online evaluator doesn't support the pipeline. To
        overcome this we created the <a href="#code/app/features/Transformer.scala">Transformer</a>. The
        transformer is a function that maps a string (e.g. a tweet) to a sequence of strings.
    </div>
</body>
</html>
