<html>
<head>
    <title>Twitter Sentiment Analysis with Apache Spark, MLlib, Scala, Akka, and Play Framework</title>
</head>
<body>
<div>
    <h2 id="twitter-sentiment-analysis">Twitter Sentiment Analysis</h2>
    <h3>powered by Apache Spark, MLlib, Scala, Akka, and Play Framework</h3>

    <p>
        With this tutorial template we show how to automatically classify the sentiment of Twitter messages leveraging the Typesafe Stack and Apache Spark. These messages are classified as either positive or negative with respect to a query term. Users who want to research the sentiment of products before purchase, or companies that want to monitor the public sentiment of their brands can make use of this kind of application. The Activator template will consist of a backend component using Scala, Spark, Akka and the Play Framework in their most recent versions. The core part will demonstrate the usage of machine learning algorithms for classifying the sentiment of Twitter messages using Apache Spark and MLlib. The fundamental idea of sentiment classification used in this template is based on <a href="http://cs.stanford.edu/people/alecmgo/papers/TwitterDistantSupervision09.pdf"  target="_blank">the paper by Alec Go et al.]</a> and its related implementation by <a  href="http://www.sentiment140.com"  target="_blank">Sentiment140</a>.
    </p>
</div>
<div>
    <h2 id="setup-instructions">Setup Instructions</h2>

    <p>
      <ol>
        <li>
      To run the application you will need <a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html"  target="_blank">Java </a> and either <a href="http://www.scala-sbt.org" target="_blank">SBT</a> or <a href="https://typesafe.com/activator" target="_blank">Activator</a> installed.</li>

  <li>Insert your Twitter access and consumer key/token pairs in <a href="#code/conf/application.conf">conf/application.conf</a>. For generating a token, please refer to <a href="https://dev.twitter.com/oauth/overview/application-owner-access-tokens"  target="_blank">https://dev.twitter.com</a> (Support fo OAuth will be added <a href="https://github.com/openforce/spark-mllib-scala-play/issues/6" target="_blank">soon</a>).</li>
</ol>
</div><div><h2 id="starting-activator-or-sbt">Starting Activator or SBT</h2>

<p>Open a terminal and navigate to the root directory of this project</p>

<p>If you have Activator installed and it is in your path you can use Activator&rsquo;s UI with <code>activator ui</code>. It will start Activator and open the web-based UI in your browser automatically. (If not, open <a href="http://localhost:8888" target="_blank">localhost:8888</a> in your browser.)</p>
<p>With in the Activator UI you can use the <a class="shortcut" href="#run">run</a> link to start the Twitter Sentiment Analysis Application.</p>

<p>
If you want to start it via SBT use <code>sbt run</code> and navigate your browser to <a href="http://localhost:9000" target="_blank">localhost:9000</a>.
</p>

</div><div><h2 id="building-and-testing">Building and Testing</h2>

<p>To ensure that the basic environment is working, compile the code and run the tests. You can use the Activator UI&rsquo;s <a class="shortcut" href="#test">test</a> link or the sbt command <code>sbt test</code>.</p>

<p>All dependencies are downloaded, the code is compiled, and the tests are executed. This will take a while the first time and the tests should pass without error.</p>
</div>

<div>
    <h2 id="classification-workflow">Classification Workflow</h2>

    <p>
        The following diagram shows how the actor communication workflow for classification looks like:.
    </p>

    <img src="tutorial/images/actors.jpg"></img>

    <p>The <a href="#code/app/controllers/Application.scala">Application</a> controller serves HTTP requests from the client/browser and obtains <code>ActorRefs</code> for <a href="#code/app/actors/EventServer.scala">EventServer</a>, <a href="#code/app/actors/StatisticsServer.scala">StatisticsServer</a> and <a href="#code/app/actors/Director.scala">Director</a>.</p>

<p>The <a href="#code/app/actors/Director.scala">Director</a> is the root of the Actor hierarchy, which creates all other durable (long lived) actors except <a href="#code/app/actors/StatisticsServer.scala">StatisticsServer</a>  and <a href="#code/app/actors/EventServer.scala">EventServer</a>. Besides supervision of the child actors it builds the bridge between Play and Akka by handing over the <a href="#code/app/actors/Classifier.scala">Classifier</a> <code>ActorRefs</code> to the controller. Moreover, when trainings of the estimators within <a href="#code/app/actors/BatchTrainer.scala">BatchTrainer</a> and <a href="#code/app/actors/OnlineTrainer.scala">OnlineTrainer</a> are finished, this actor passes the latest Machine Learning models to the <a href="#code/app/actors/StatisticsServer">StatisticsServer</a> (see figure below). For the <a href="#code/app/actors/OnlineTrainer">OnlineTrainer</a> statistics generation is scheduled every 5 seconds.
</p>


The <a href="#code/app/actors/Classifier.scala">Classifier</a> creates a <a href="#code/app/actors/Classifier.scala">FetchResponseHandler</a> actor and tells the <code>TwitterHandler</code> with a <code>Fetch</code> message (and the <code>ActorRef</code> of the <a href="#code/app/actors/Classifier.scala">FetchResponseHandler</a>) to get the latest tweets by a given token or query.

Once the <code>TwitterHandler</code> has fetched some Tweets, the <code>FetchResponse</code> is sent to the <a href="#code/app/actors/Classifier.scala">FetchResponseHandler</a>.

The <a href="#code/app/actors/Classifier.scala">FetchResponseHandler</a> creates a <code>TrainingModelResponseHandler</code> actor and tells the <a href="#code/app/actors/BatchTrainer.scala">BatchTrainer</a> and <a href="#code/app/actors/OnlineTrainer.scala">OnlineTrainer</a> to pass the latest model to <code>TrainingModelResponseHandler</code>. It registers itself as a monitor for <code>TrainingModelResponseHandler</code> and when this actor terminates it stops itself as well.

The <code>TrainingModelResponseHandler</code> collects the models and vectorized Tweets makes predictions and sends the results to the original sender (the <a href="#code/app/controllers/Application.scala">Application</a> controller). The original sender is passed through the ephemeral (short lived) actors, indicated by the yellow dotted line in the figure above.

</div>
<div>
    <h2 id="model-training-and-statistics">Model Training and Statistics</h2>

    <p>
      The following diagram shows the actors involved in training the machine learning estimators and serving statistics about their predictive performance:

      <img src="tutorial/images/actors2.jpg"></img>

<p>
  The <a href="#code/app/actors/BatchTrainer.scala">BatchTrainer</a> receives a <code>Train</code> message as soon as a corpus (a collection of labeled tweets) has been initialized. This corpus is initialized by the <a href="#code/app/actors/CorpusInitializer.scala">CorpusInitializer</a> and can either be created on-the-fly via Spark's <code>TwitterUtils.createStream</code> (with automatic labeling by using emoticons ":)" and ":(") or a static corpus provided by <a href="http://www.sentiment140.com">Sentiment140</a> which is read from a CSV file. Which one to choose can be configured via <code>ml.corpus.initialization.streamed</code> in <a href="#code/conf/application.conf">conf/application.conf</a>. For batch training we use the high-level <code>org.apache.spark.ml</code> API. We use <bold>Grid Search Cross Validation</bold> to get the best hyperparameters for our <code>LogisticRegression</code> model.
</p>
<p>
The <a href="#code/app/actors/OnlineTrainer.scala">OnlineTrainer</a> receives a <code>Train</code> message with a corpus (an <code>RDD[Tweet]</code>) upon successful initialization just like the <a href="#code/app/actors/BatchTrainer.scala">BatchTrainer</a>. For the online learning approach we use the experimental <code>StreamingLogisticRegressionWithSGD</code> estimator which, as the name implies, uses <bold>Stochastic Gradient Descent</bold> to update the model continually on each Mini-Batch (RDD) of the <code>DStream</code> created via <code>TwitterUtils.createStream</code>.
</p>
<p>
The <a href="#code/app/actors/StatisticsServer.scala">StatisticsServer</a> receives <code>OnlineTrainerModel</code> and <code>BatchTrainerModel</code> messages and creates performance metrics like <bold>Accuracy, Area under the ROC Curve</bold> and so forth which in turn are forwarded to the subscribed <code>EventListeners</code> and finally sent to the client (browser) via <bold>Web Socket</bold>.
</p>
<p>
The <a href="#code/app/actors/EventListener.scala">EventListener</a>s are created for each client via the Play Framework built-in <code>WebSocket.acceptWithActor</code>. <code>EventListeners</code> subscribe for <a href="#code/app/actors/EventServer.scala">EventServer</a> and <a href="#code/app/actors/StatisticsServer.scala">StatisticsServer</a>. When the connections terminate (e.g. browser window is closed) the respective <code>EventListener</code> shuts down and unsubscribes from <code>EventServer</code> and/or <code>StatisticsServer</code> via the Actor's <code>postStop()</code> hook.
</p>
<p>
The <a href="#code/app/actors/EventServer.scala">EventServer</a> is created by the <a href="#code/app/controllers/Application.scala">Application</a> controller and forwards event messages (progress of corpus initialization) to the client (also via <code>Web Socket</code>).
</p>
</div>
</body>
</html>
